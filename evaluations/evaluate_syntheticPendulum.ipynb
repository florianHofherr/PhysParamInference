{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for the Synthetic Pendulum Experiments\n",
    "This notebook can be used to load and analyze the results generated by running `training_syntheticPendulum.py`. The notebook is meant to evaluate multiple experiments together and compute the average Performances over all experiments. (E.g. the average performance over all 9 stonewall/woodwall/wallclock scenes, as reported in the papaer)\n",
    "\n",
    "The path to the the folder containing the experiments needs to be specified under `path_experiment`. The folder set here needs to contain the subfolders with the experiments, where those subfolders need to contain `ckpt.pth` and `./hydra/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "from models.sceneRepresentation import Scene\n",
    "from dataset.dataset import DynamicPixelDataset, get_split_dynamic_pixel_data\n",
    "from util.initialValues import estimate_initial_values\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "from util.util import compute_psnr, compute_iou\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the experiments to analyze.\n",
    "# The folder specified here needs to contain the subfolders which contain `ckpt.pth` and `./hydra/` \n",
    "path_experiments = os.path.join(\n",
    "    os.path.abspath(''),\n",
    "    'experiments',\n",
    "    '2023-01-24',\n",
    "    'synthetic',\n",
    "    'ours',\n",
    "    'stonewall'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_errors = []\n",
    "psnrs = []\n",
    "ious = []\n",
    "init_errors_A = []\n",
    "init_errors_x0 = []\n",
    "path_file = os.path.join(path_experiments, 'results.txt')\n",
    "\n",
    "# Delete previous result files\n",
    "if os.path.exists(path_file):\n",
    "    os.remove(path_file)\n",
    "\n",
    "# Get all the experiments\n",
    "for path_experiment in os.scandir(path_experiments):\n",
    "    # Load Config\n",
    "    path_conf = os.path.join(path_experiment, '.hydra','config.yaml')\n",
    "    with open(path_conf) as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    print(\"Doing: \", cfg['data']['path_data'])\n",
    "\n",
    "    # Load Model\n",
    "    model = Scene(**cfg['scene']['background'])\n",
    "    model.add_pendulum(**cfg['ode'], **cfg['scene']['local_representation'])\n",
    "\n",
    "    path_ckpt = os.path.join(path_experiment, 'ckpt.pth')\n",
    "    model.load_state_dict(torch.load(path_ckpt))\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Load Data\n",
    "    train_data, test_data = get_split_dynamic_pixel_data(**cfg['data'])\n",
    "    H, W = test_data.get_image_dim()\n",
    "    tspan = train_data.parameters[\"tspan\"].to(device)\n",
    "\n",
    "    # Compute errors of init values\n",
    "    init_values_estimate = estimate_initial_values(\n",
    "        train_data.get_full_mask(),\n",
    "        train_data.get_pixel_coords(),\n",
    "        tspan\n",
    "    )\n",
    "    rel_error_init_A = (torch.norm(test_data.get_image_dim()[0]*init_values_estimate['A'] - test_data.parameters['A']) /\n",
    "                        torch.norm(test_data.parameters['A']))\n",
    "    rel_error_init_x0 = torch.norm(init_values_estimate['x0'] - test_data.parameters['x0']) / torch.norm(test_data.parameters['x0'])\n",
    "    init_errors_A.append(rel_error_init_A)\n",
    "    init_errors_x0.append(rel_error_init_x0)\n",
    "\n",
    "    # Compute Parameter Errors\n",
    "    rel_error_A = torch.norm(test_data.parameters['A'] - W*model.local_representation.A.cpu()) / torch.norm(test_data.parameters['A'])\n",
    "    rel_error_c = torch.abs(test_data.parameters['c'] - model.local_representation.ode.c.cpu()) / test_data.parameters['c']\n",
    "    rel_error_l = torch.abs(test_data.parameters['l_pendulum'] - model.local_representation.ode.l_pendulum.cpu()) / test_data.parameters['l_pendulum']\n",
    "    rel_error_x0 = torch.norm(test_data.parameters['x0'] - model.local_representation.x0.cpu()) / torch.norm(test_data.parameters['x0'])\n",
    "    param_errors.append(rel_error_A)\n",
    "    param_errors.append(rel_error_c)\n",
    "    param_errors.append(rel_error_l)\n",
    "    param_errors.append(rel_error_x0)\n",
    "\n",
    "    # Compute PSNR and IoU\n",
    "    tspan = test_data.parameters[\"tspan\"].to(device)\n",
    "    model.update_trafo(tspan)\n",
    "    output = model.render_image(W, H)\n",
    "    psnr = compute_psnr(output['Image'].cpu(), test_data.get_full_images())\n",
    "    iou = compute_iou(output['Mask'].cpu(), test_data.get_full_mask())\n",
    "    psnrs.append(psnr)\n",
    "    ious.append(iou)\n",
    "\n",
    "    # Write summary file\n",
    "    with open(path_file, 'a') as f:\n",
    "        f.write(f\"{cfg['data']['path_data']}\\n\")\n",
    "        f.write(f\"{path_experiment.path}\\n\")\n",
    "        f.write(f\"Rel Error init A: {rel_error_init_A}\\n\")\n",
    "        f.write(f\"Rel Error init x0: {rel_error_init_x0}\\n\")\n",
    "        f.write(f\"Rel Error A: {rel_error_A}\\n\")\n",
    "        f.write(f\"Rel Error c: {rel_error_c.data}\\n\")\n",
    "        f.write(f\"Rel Error l: {rel_error_l.data}\\n\")\n",
    "        f.write(f\"Rel Error x0: {rel_error_x0}\\n\")\n",
    "        f.write(f\"PSNR: {psnr}\\n\")\n",
    "        f.write(f\"IoU: {iou}\\n\")\n",
    "        f.write(\"=============================\\n\\n\")\n",
    "\n",
    "    mean_errors = torch.mean(torch.tensor([rel_error_A, rel_error_c, rel_error_l, rel_error_x0]))\n",
    "    print(f\"Mean Errors: {mean_errors}, PSNR: {psnr}, IoU: {iou}\")\n",
    "\n",
    "    print(\"Done\")\n",
    "    print(\"====================================================\")\n",
    "\n",
    "avg_param_error = torch.mean(torch.tensor(param_errors))\n",
    "avg_init_errors_A = torch.mean(torch.tensor(init_errors_A))\n",
    "avg_init_errors_x0 = torch.mean(torch.tensor(init_errors_x0))\n",
    "avg_psnr = torch.mean(torch.tensor(psnrs))\n",
    "avg_iou = torch.mean(torch.tensor(ious))\n",
    "print(\"Results:\")\n",
    "print(f\"Avg Param Error: {avg_param_error}, Avg PSNR: {avg_psnr}, Avg IoU: {avg_iou}, Avg Init Error A: {avg_init_errors_A}, Avg Init Error x0: {avg_init_errors_x0}\")\n",
    "\n",
    "# Write to results file\n",
    "with open(path_file, 'a') as f:\n",
    "    f.write(f\"Avg Init Error A: {avg_init_errors_A}, Avg Init Error x0: {avg_init_errors_x0}\\n\")\n",
    "    f.write(\"\\nLatex\\n\")\n",
    "    f.write(f\"{avg_psnr:.2f} & {avg_iou:.2f} & {(100*avg_param_error):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Images\n",
    "The following code creates images for a specific experiment. The folder containing `ckpt.pth` and `./hydra/` for this experiment needs to be specified under `path_experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_experiment = os.path.join(\n",
    "    os.path.abspath(''),\n",
    "    'experiments',\n",
    "    '2023-01-24',\n",
    "    'synthetic',\n",
    "    'ours',\n",
    "    'stonewall',\n",
    "    '13-07-44_seq1'\n",
    ")\n",
    "\n",
    "path_folder = os.path.join(path_experiment, 'renderings')\n",
    "if not os.path.isdir(path_folder):\n",
    "    os.makedirs(path_folder)\n",
    "\n",
    "# Load Config\n",
    "path_conf = os.path.join(path_experiment, '.hydra','config.yaml')\n",
    "with open(path_conf) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Load Model\n",
    "model = Scene(**cfg['scene']['background'])\n",
    "model.add_pendulum(**cfg['ode'], **cfg['scene']['local_representation'])\n",
    "\n",
    "path_ckpt = os.path.join(path_experiment, 'ckpt.pth')\n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "# Load Data\n",
    "path_data = os.path.join(os.path.abspath(''), 'data',cfg['data']['path_data'])\n",
    "data = DynamicPixelDataset(\n",
    "    path_data,\n",
    "    skip_timesteps=cfg['data']['skip_timesteps'],\n",
    "    max_samples=cfg['data']['max_samples']\n",
    ")\n",
    "H, W = data.get_image_dim()\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Render\n",
    "tspan = data.parameters[\"tspan\"].to(device)\n",
    "print(tspan)\n",
    "model.update_trafo(tspan)\n",
    "output = model.render_image(W, H)\n",
    "ims = output[\"Image\"].cpu()\n",
    "masks = output['Mask'].cpu()\n",
    "\n",
    "plt.imshow(ims[0])\n",
    "\n",
    "# Train data\n",
    "inds_to_save = [0, 1]\n",
    "\n",
    "for i in inds_to_save:\n",
    "    path = os.path.join(path_folder, f\"{i}_train.jpg\")\n",
    "    utils.save_image(ims[i].permute(2, 0, 1), path)\n",
    "    path = os.path.join(path_folder, f\"{i}_mask_train.jpg\")\n",
    "    utils.save_image(masks[i], path)\n",
    "    path = os.path.join(path_folder, f\"{i}_gt_train.jpg\")\n",
    "    utils.save_image(data.get_full_images(i).permute(2, 0, 1), path)\n",
    "    path = os.path.join(path_folder, f\"{i}_mask_gt_train.jpg\")\n",
    "    utils.save_image(data.get_full_mask(i), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "# Load Data\n",
    "path_data = os.path.join(os.path.abspath(''), 'data',cfg['data']['path_data'])\n",
    "data = DynamicPixelDataset(\n",
    "    path_data,\n",
    "    start_index=cfg['data']['start_idx_test'],\n",
    "    max_samples=cfg['data']['max_samples_eval'],\n",
    "    skip_timesteps=cfg['data']['skip_timesteps'],\n",
    ")\n",
    "H, W = data.get_image_dim()\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Render\n",
    "tspan = data.parameters[\"tspan\"].to(device)\n",
    "print(tspan)\n",
    "model.update_trafo(tspan)\n",
    "output = model.render_image(W, H)\n",
    "ims = output[\"Image\"].cpu()\n",
    "masks = output['Mask'].cpu()\n",
    "\n",
    "plt.imshow(ims[0])\n",
    "\n",
    "# Train data\n",
    "inds_to_save = [5, 22]\n",
    "print(f\"Storing at times {tspan[inds_to_save[0]]} and {tspan[inds_to_save[1]]}\")\n",
    "\n",
    "for i in inds_to_save:\n",
    "    path = os.path.join(path_folder, f\"{i}_test.jpg\")\n",
    "    utils.save_image(ims[i].permute(2, 0, 1), path)\n",
    "    path = os.path.join(path_folder, f\"{i}_mask_test.jpg\")\n",
    "    utils.save_image(masks[i], path)\n",
    "    path = os.path.join(path_folder, f\"{i}_gt_test.jpg\")\n",
    "    utils.save_image(data.get_full_images(i).permute(2, 0, 1), path)\n",
    "    path = os.path.join(path_folder, f\"{i}_mask_gt_test.jpg\")\n",
    "    utils.save_image(data.get_full_mask(i), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nerf-pytorch3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f01482bfefa3a3bc7460951111586304597956327628e7e66e099af897f7956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
