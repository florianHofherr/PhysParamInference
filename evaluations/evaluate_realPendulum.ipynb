{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for the Real Pendulum Experiments\n",
    "This notebook can be used to load and analyze the results generated by running `training_realPendulum.py`. The path to the the folder containing `ckpt.pth` and `./hydra/` needs to be specified under `path_experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from torchvision import utils\n",
    "from models.sceneRepresentation import Scene\n",
    "from dataset.dataset import ImageDataset_realData\n",
    "from util.util import compute_psnr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the results (/.hydra/, ckpt.pth)\n",
    "path_experiment = os.path.join(\n",
    "    os.path.abspath(''),\n",
    "    'experiments',\n",
    "    '2023-01-24',\n",
    "    'real_world',\n",
    "    'pendulum',\n",
    "    '10-20-22'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config and the checkpoint\n",
    "path_conf = os.path.join(path_experiment, '.hydra','config.yaml')\n",
    "with open(path_conf) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "model = Scene(**cfg['scene']['background'])\n",
    "\n",
    "model.add_pendulum(**cfg['ode'], **cfg['scene']['local_representation'])\n",
    "\n",
    "path_ckpt = os.path.join(path_experiment, 'ckpt.pth')\n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "\n",
    "model.use_homography = cfg['homography']['enable']\n",
    "\n",
    "model.to(device)\n",
    "print(\"Moved to device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = os.path.join(os.path.abspath(''), 'data',cfg['data']['path_data'])\n",
    "\n",
    "train_data = ImageDataset_realData(\n",
    "    **cfg['data'],\n",
    "    normalize_by_H=True,\n",
    "    max_samples=cfg['data']['samples_train']\n",
    ")\n",
    "\n",
    "eval_data = ImageDataset_realData(\n",
    "    **cfg['data'],\n",
    "    normalize_by_H=True,\n",
    "    indices=train_data.unused_inds\n",
    ")\n",
    "\n",
    "tspan_eval = eval_data.t_steps.to(device)\n",
    "print(f\"Tspan eval data: {tspan_eval}\")\n",
    "print(f\"Tspan train data: {train_data.t_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render images and evaluate\n",
    "model.eval()\n",
    "model.update_trafo(tspan_eval)\n",
    "H, W = eval_data.get_image_dim()\n",
    "output = model.render_image(W, H, normalize_by_H=True)\n",
    "ims = output[\"Image\"].cpu()\n",
    "masks = output['Mask'].cpu()\n",
    "\n",
    "psnr = compute_psnr(ims, eval_data.get_full_images())\n",
    "norm = torch.norm(torch.eye(3) - model.homography_matrix.cpu())\n",
    "\n",
    "measured_l = 0.271\n",
    "rel_error_l = torch.abs(model.local_representation.ode.l_pendulum - measured_l) / measured_l\n",
    "print(f\"PSNR: {psnr}, Norm diff: {norm}\")\n",
    "print(f\"Rel Error l: {100*rel_error_l:.2f}%\")\n",
    "print(f\"{psnr:.2f} & {norm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the renderings to the experiments folder\n",
    "path_folder_rendering = os.path.join(path_experiment, 'renderingsRealWorld')\n",
    "os.makedirs(path_folder_rendering)\n",
    "\n",
    "width = int(ims.shape[2] / 2 - 2)\n",
    "\n",
    "inds_to_save = [i for i in range(8, 15) if (i+1)%1==0]\n",
    "print(f\"Saving imgaes for timesteps {tspan_eval[inds_to_save]}\")\n",
    "\n",
    "# Save individual images\n",
    "for i in inds_to_save:\n",
    "    path = os.path.join(path_folder_rendering, f\"{i}_eval.jpg\")\n",
    "    cur_im = ims[i].permute(2, 0, 1)\n",
    "    utils.save_image(cur_im, path)\n",
    "\n",
    "    path = os.path.join(path_folder_rendering, f\"{i}_gt.jpg\")\n",
    "    cur_im_gt = eval_data.get_full_images(i).permute(2, 0, 1)\n",
    "    utils.save_image(cur_im_gt, path)\n",
    "\n",
    "    path = os.path.join(path_folder_rendering, f\"{i}_mask_eval.jpg\")\n",
    "    cur_mask = masks[i]\n",
    "    utils.save_image(cur_mask, path)\n",
    "\n",
    "    path = os.path.join(path_folder_rendering, f\"{i}_merged_gtRight.jpg\")\n",
    "    merged_im = torch.zeros_like(cur_im)\n",
    "    merged_im[0, :, :] = 1.0\n",
    "    merged_im[:, :, :width] = cur_im[:, :, :width]\n",
    "    merged_im[:, :, -width:] = cur_im_gt[:, :, -width:]\n",
    "    utils.save_image(merged_im, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nerf-pytorch3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f01482bfefa3a3bc7460951111586304597956327628e7e66e099af897f7956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
